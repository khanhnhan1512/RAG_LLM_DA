{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2014-01-01': 1, '2014-01-02': 2, '2014-01-03': 3, '2014-01-04': 4, '2014-01-05': 5, '2014-01-06': 6, '2014-01-07': 7, '2014-01-08': 8, '2014-01-09': 9, '2014-01-10': 10, '2014-01-11': 11, '2014-01-12': 12, '2014-01-13': 13, '2014-01-14': 14, '2014-01-15': 15, '2014-01-16': 16, '2014-01-17': 17, '2014-01-18': 18, '2014-01-19': 19, '2014-01-20': 20, '2014-01-21': 21, '2014-01-22': 22, '2014-01-23': 23, '2014-01-24': 24, '2014-01-25': 25, '2014-01-26': 26, '2014-01-27': 27, '2014-01-28': 28, '2014-01-29': 29, '2014-01-30': 30, '2014-01-31': 31, '2014-02-01': 32, '2014-02-02': 33, '2014-02-03': 34, '2014-02-04': 35, '2014-02-05': 36, '2014-02-06': 37, '2014-02-07': 38, '2014-02-08': 39, '2014-02-09': 40, '2014-02-10': 41, '2014-02-11': 42, '2014-02-12': 43, '2014-02-13': 44, '2014-02-14': 45, '2014-02-15': 46, '2014-02-16': 47, '2014-02-17': 48, '2014-02-18': 49, '2014-02-19': 50, '2014-02-20': 51, '2014-02-21': 52, '2014-02-22': 53, '2014-02-23': 54, '2014-02-24': 55, '2014-02-25': 56, '2014-02-26': 57, '2014-02-27': 58, '2014-02-28': 59, '2014-03-01': 60, '2014-03-02': 61, '2014-03-03': 62, '2014-03-04': 63, '2014-03-05': 64, '2014-03-06': 65, '2014-03-07': 66, '2014-03-08': 67, '2014-03-09': 68, '2014-03-10': 69, '2014-03-11': 70, '2014-03-12': 71, '2014-03-13': 72, '2014-03-14': 73, '2014-03-15': 74, '2014-03-16': 75, '2014-03-17': 76, '2014-03-18': 77, '2014-03-19': 78, '2014-03-20': 79, '2014-03-21': 80, '2014-03-22': 81, '2014-03-23': 82, '2014-03-24': 83, '2014-03-25': 84, '2014-03-26': 85, '2014-03-27': 86, '2014-03-28': 87, '2014-03-29': 88, '2014-03-30': 89, '2014-03-31': 90, '2014-04-01': 91, '2014-04-02': 92, '2014-04-03': 93, '2014-04-04': 94, '2014-04-05': 95, '2014-04-06': 96, '2014-04-07': 97, '2014-04-08': 98, '2014-04-09': 99, '2014-04-10': 100, '2014-04-11': 101, '2014-04-12': 102, '2014-04-13': 103, '2014-04-14': 104, '2014-04-15': 105, '2014-04-16': 106, '2014-04-17': 107, '2014-04-18': 108, '2014-04-19': 109, '2014-04-20': 110, '2014-04-21': 111, '2014-04-22': 112, '2014-04-23': 113, '2014-04-24': 114, '2014-04-25': 115, '2014-04-26': 116, '2014-04-27': 117, '2014-04-28': 118, '2014-04-29': 119, '2014-04-30': 120, '2014-05-01': 121, '2014-05-02': 122, '2014-05-03': 123, '2014-05-04': 124, '2014-05-05': 125, '2014-05-06': 126, '2014-05-07': 127, '2014-05-08': 128, '2014-05-09': 129, '2014-05-10': 130, '2014-05-11': 131, '2014-05-12': 132, '2014-05-13': 133, '2014-05-14': 134, '2014-05-15': 135, '2014-05-16': 136, '2014-05-17': 137, '2014-05-18': 138, '2014-05-19': 139, '2014-05-20': 140, '2014-05-21': 141, '2014-05-22': 142, '2014-05-23': 143, '2014-05-24': 144, '2014-05-25': 145, '2014-05-26': 146, '2014-05-27': 147, '2014-05-28': 148, '2014-05-29': 149, '2014-05-30': 150, '2014-05-31': 151, '2014-06-01': 152, '2014-06-02': 153, '2014-06-03': 154, '2014-06-04': 155, '2014-06-05': 156, '2014-06-06': 157, '2014-06-07': 158, '2014-06-08': 159, '2014-06-09': 160, '2014-06-10': 161, '2014-06-11': 162, '2014-06-12': 163, '2014-06-13': 164, '2014-06-14': 165, '2014-06-15': 166, '2014-06-16': 167, '2014-06-17': 168, '2014-06-18': 169, '2014-06-19': 170, '2014-06-20': 171, '2014-06-21': 172, '2014-06-22': 173, '2014-06-23': 174, '2014-06-24': 175, '2014-06-25': 176, '2014-06-26': 177, '2014-06-27': 178, '2014-06-28': 179, '2014-06-29': 180, '2014-06-30': 181, '2014-07-01': 182, '2014-07-02': 183, '2014-07-03': 184, '2014-07-04': 185, '2014-07-05': 186, '2014-07-06': 187, '2014-07-07': 188, '2014-07-08': 189, '2014-07-09': 190, '2014-07-10': 191, '2014-07-11': 192, '2014-07-12': 193, '2014-07-13': 194, '2014-07-14': 195, '2014-07-15': 196, '2014-07-16': 197, '2014-07-17': 198, '2014-07-18': 199, '2014-07-19': 200, '2014-07-20': 201, '2014-07-21': 202, '2014-07-22': 203, '2014-07-23': 204, '2014-07-24': 205, '2014-07-25': 206, '2014-07-26': 207, '2014-07-27': 208, '2014-07-28': 209, '2014-07-29': 210, '2014-07-30': 211, '2014-07-31': 212, '2014-08-01': 213, '2014-08-02': 214, '2014-08-03': 215, '2014-08-04': 216, '2014-08-05': 217, '2014-08-06': 218, '2014-08-07': 219, '2014-08-08': 220, '2014-08-09': 221, '2014-08-10': 222, '2014-08-11': 223, '2014-08-12': 224, '2014-08-13': 225, '2014-08-14': 226, '2014-08-15': 227, '2014-08-16': 228, '2014-08-17': 229, '2014-08-18': 230, '2014-08-19': 231, '2014-08-20': 232, '2014-08-21': 233, '2014-08-22': 234, '2014-08-23': 235, '2014-08-24': 236, '2014-08-25': 237, '2014-08-26': 238, '2014-08-27': 239, '2014-08-28': 240, '2014-08-29': 241, '2014-08-30': 242, '2014-08-31': 243, '2014-09-01': 244, '2014-09-02': 245, '2014-09-03': 246, '2014-09-04': 247, '2014-09-05': 248, '2014-09-06': 249, '2014-09-07': 250, '2014-09-08': 251, '2014-09-09': 252, '2014-09-10': 253, '2014-09-11': 254, '2014-09-12': 255, '2014-09-13': 256, '2014-09-14': 257, '2014-09-15': 258, '2014-09-16': 259, '2014-09-17': 260, '2014-09-18': 261, '2014-09-19': 262, '2014-09-20': 263, '2014-09-21': 264, '2014-09-22': 265, '2014-09-23': 266, '2014-09-24': 267, '2014-09-25': 268, '2014-09-26': 269, '2014-09-27': 270, '2014-09-28': 271, '2014-09-29': 272, '2014-09-30': 273, '2014-10-01': 274, '2014-10-02': 275, '2014-10-03': 276, '2014-10-04': 277, '2014-10-05': 278, '2014-10-06': 279, '2014-10-07': 280, '2014-10-08': 281, '2014-10-09': 282, '2014-10-10': 283, '2014-10-11': 284, '2014-10-12': 285, '2014-10-13': 286, '2014-10-14': 287, '2014-10-15': 288, '2014-10-16': 289, '2014-10-17': 290, '2014-10-18': 291, '2014-10-19': 292, '2014-10-20': 293, '2014-10-21': 294, '2014-10-22': 295, '2014-10-23': 296, '2014-10-24': 297, '2014-10-25': 298, '2014-10-26': 299, '2014-10-27': 300, '2014-10-28': 301, '2014-10-29': 302, '2014-10-30': 303, '2014-10-31': 304, '2014-11-01': 305, '2014-11-02': 306, '2014-11-03': 307, '2014-11-04': 308, '2014-11-05': 309, '2014-11-06': 310, '2014-11-07': 311, '2014-11-08': 312, '2014-11-09': 313, '2014-11-10': 314, '2014-11-11': 315, '2014-11-12': 316, '2014-11-13': 317, '2014-11-14': 318, '2014-11-15': 319, '2014-11-16': 320, '2014-11-17': 321, '2014-11-18': 322, '2014-11-19': 323, '2014-11-20': 324, '2014-11-21': 325, '2014-11-22': 326, '2014-11-23': 327, '2014-11-24': 328, '2014-11-25': 329, '2014-11-26': 330, '2014-11-27': 331, '2014-11-28': 332, '2014-11-29': 333, '2014-11-30': 334, '2014-12-01': 335, '2014-12-02': 336, '2014-12-03': 337, '2014-12-04': 338, '2014-12-05': 339, '2014-12-06': 340, '2014-12-07': 341, '2014-12-08': 342, '2014-12-09': 343, '2014-12-10': 344, '2014-12-11': 345, '2014-12-12': 346, '2014-12-13': 347, '2014-12-14': 348, '2014-12-15': 349, '2014-12-16': 350, '2014-12-17': 351, '2014-12-18': 352, '2014-12-19': 353, '2014-12-20': 354, '2014-12-21': 355, '2014-12-22': 356, '2014-12-23': 357, '2014-12-24': 358, '2014-12-25': 359, '2014-12-26': 360, '2014-12-27': 361, '2014-12-28': 362, '2014-12-29': 363, '2014-12-30': 364, '2014-12-31': 365}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime, timedelta  \n",
    "\n",
    "class DateMapper:  \n",
    "    def __init__(self, year=2014):  \n",
    "        self.year = year  \n",
    "        self.start_date = datetime(year, 1, 1)  \n",
    "        self.date_to_id_map = {}  \n",
    "        self.id_to_date_map = {}  \n",
    "        self._build_mappings()  \n",
    "\n",
    "    def _build_mappings(self):  \n",
    "        \"\"\"Xây dựng mapping hai chiều\"\"\"  \n",
    "        current_date = self.start_date  \n",
    "        for day_id in range(1, 367):  # 366 ngày cho năm nhuận  \n",
    "            if current_date.year != self.year:\n",
    "                break\n",
    "            date_str = current_date.strftime('%Y-%m-%d')  \n",
    "            self.date_to_id_map[date_str] = day_id  \n",
    "            self.id_to_date_map[day_id] = date_str  \n",
    "            current_date += timedelta(days=1)  \n",
    "\n",
    "    def date_to_id(self, date_str):  \n",
    "        \"\"\"Chuyển đổi ngày thành ID\"\"\"  \n",
    "        try:  \n",
    "            return self.date_to_id_map[date_str]  \n",
    "        except KeyError:  \n",
    "            raise ValueError(f\"Invalid date or date not in year {self.year}: {date_str}\")  \n",
    "\n",
    "    def id_to_date(self, day_id):  \n",
    "        \"\"\"Chuyển đổi ID thành ngày\"\"\"  \n",
    "        try:  \n",
    "            return self.id_to_date_map[day_id]  \n",
    "        except KeyError:  \n",
    "            raise ValueError(f\"Invalid ID. Must be between 1 and 366\")  \n",
    "\n",
    "    def convert_dates(self, dates):  \n",
    "        \"\"\"Chuyển đổi nhiều ngày cùng lúc\"\"\"  \n",
    "        return [self.date_to_id(date) for date in dates]\n",
    "\n",
    "    def save_to_json(self, filename):\n",
    "        \"\"\"Lưu mapping ngày sang ID vào file JSON\"\"\"\n",
    "        with open(filename, 'w') as json_file:\n",
    "            json.dump(self.date_to_id_map, json_file, indent=4)\n",
    "\n",
    "# Sử dụng  \n",
    "mapper = DateMapper(2014)  \n",
    "\n",
    "# Lưu mapping vào file JSON\n",
    "mapper.save_to_json('date_to_id_mapping_2014.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add test_inv for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = ['subject', 'relation', 'object', 'timestamp']\n",
    "df = pd.read_csv('../datasets/icews18/test.txt', sep='\\t', names=columns)\n",
    "# tạo 1 df mới với cột subject và object ngược lại với df cũ, riêng cột relation của df mới này sẽ có thêm 'inv_' ở trước\n",
    "df_inv = df.copy()\n",
    "df_inv['subject'] = df['object']\n",
    "df_inv['object'] = df['subject']\n",
    "df_inv['relation'] = 'inv_' + df['relation']\n",
    "# gộp 2 df lại với nhau\n",
    "df = pd.concat([df, df_inv], ignore_index=True)\n",
    "df.to_csv('../datasets/icews18/test.txt.inv', sep='\\t', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify JSON output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working folder: D:\\My Document\\Khóa Luận Tốt Nghiệp\\Model Reposity\\RAG_LLM_DA\n",
      "Current working folder: D:\\My Document\\Khóa Luận Tốt Nghiệp\\Model Reposity\\RAG_LLM_DA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"Current working folder: {os.getcwd()}\")\n",
    "\n",
    "os.chdir('D:/My Document/Khóa Luận Tốt Nghiệp/Model Reposity/RAG_LLM_DA')\n",
    "print(f\"Current working folder: {os.getcwd()}\")\n",
    "\n",
    "from utils import load_json_data, save_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from result/icews14/stage_4/final_candidates.json\n",
      "Data has been converted to JSON and saved to ./final_candidates.json\n"
     ]
    }
   ],
   "source": [
    "x = load_json_data('result/icews14/stage_4/final_candidates.json')\n",
    "# delete keys from '7371' to '14741'\n",
    "for i in range(7371, 14742):\n",
    "    del x[str(i)]\n",
    "save_json_data(x, './final_candidates.json', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working folder: c:\\Users\\UHY6HC\\Downloads\\Thesis\\RAG_LLM_DA\\notebooks\n",
      "Current working folder: C:\\Users\\UHY6HC\\Downloads\\Thesis\\RAG_LLM_DA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"Current working folder: {os.getcwd()}\")\n",
    "\n",
    "os.chdir('C:/Users/UHY6HC/Downloads/Thesis/RAG_LLM_DA')\n",
    "print(f\"Current working folder: {os.getcwd()}\")\n",
    "\n",
    "from utils import load_json_data, write_lines_to_file, read_lines_from_file, save_json_data\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "source_data = \"datasets/YAGO\"\n",
    "destination_data = \"datasets/icews14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from datasets/YAGO\\entity2id.json\n"
     ]
    }
   ],
   "source": [
    "entity_list = list(load_json_data(os.path.join(source_data, 'entity2id.json')).keys())\n",
    "write_lines_to_file(os.path.join(source_data, 'entities.txt'), entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from datasets/YAGO\\ts2id.json\n",
      "Data has been converted to JSON and saved to datasets/YAGO\\ts2id.json\n"
     ]
    }
   ],
   "source": [
    "ts2id = load_json_data(os.path.join(source_data, 'ts2id.json'))\n",
    "new_ts2id = {f\"T_{k}\": v for k,v in ts2id.items()}\n",
    "save_json_data(new_ts2id, os.path.join(source_data, 'ts2id.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['subject', 'relation', 'object', 'timestamp', 'temp']\n",
    "for f in ['train_.txt', 'valid_.txt', 'test_.txt']:\n",
    "    df = pd.read_csv(os.path.join(source_data, f), sep='\\t', header=None, names=columns)\n",
    "    df = df.drop('temp', axis=1)\n",
    "    df.to_csv(os.path.join(source_data, f), sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Balleroy</td>\n",
       "      <td>Instance_of</td>\n",
       "      <td>Communes_In_France</td>\n",
       "      <td>T_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Selman_Waksman</td>\n",
       "      <td>Educated_at</td>\n",
       "      <td>Rutger'S_University</td>\n",
       "      <td>T_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charles_Macintosh</td>\n",
       "      <td>Country_of_citizenship</td>\n",
       "      <td>United_Kingdom_Of_Great_Britain</td>\n",
       "      <td>T_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Montigny-Le-Gannelon</td>\n",
       "      <td>Instance_of</td>\n",
       "      <td>Communes_In_France</td>\n",
       "      <td>T_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France_Metropolitan</td>\n",
       "      <td>Contains_administrative_territorial_entity</td>\n",
       "      <td>Nord-Pas_De_Calais</td>\n",
       "      <td>T_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                subject                                    relation  \\\n",
       "0              Balleroy                                 Instance_of   \n",
       "1        Selman_Waksman                                 Educated_at   \n",
       "2     Charles_Macintosh                      Country_of_citizenship   \n",
       "3  Montigny-Le-Gannelon                                 Instance_of   \n",
       "4   France_Metropolitan  Contains_administrative_territorial_entity   \n",
       "\n",
       "                            object timestamp  \n",
       "0               Communes_In_France       T_0  \n",
       "1              Rutger'S_University       T_0  \n",
       "2  United_Kingdom_Of_Great_Britain       T_0  \n",
       "3               Communes_In_France       T_0  \n",
       "4               Nord-Pas_De_Calais       T_0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['subject', 'relation', 'object', 'timestamp']\n",
    "df = pd.read_csv(os.path.join(source_data, 'all_facts.txt'), sep='\\t', header=None, names=columns)\n",
    "new_ts = []\n",
    "for _, row in df.iterrows():\n",
    "    new_ts.append(f\"T_{row['timestamp']}\")\n",
    "\n",
    "df['timestamp'] = new_ts\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[:220393]\n",
    "train_df.to_csv(os.path.join(source_data, 'train.txt'), sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = df.iloc[220393:249341]\n",
    "valid_df.to_csv(os.path.join(source_data, 'valid.txt'), sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_df = df.iloc[:249341]\n",
    "train_valid_df.to_csv(os.path.join(source_data, 'facts.txt'), sep='\\t', header=None, index=False)\n",
    "\n",
    "inv_facts_rows = []\n",
    "for _, row in train_valid_df.iterrows():\n",
    "    inv_facts_rows.append(row)\n",
    "    inv_row = row.copy()\n",
    "    inv_row['subject'], inv_row['object'] = row['object'], row['subject']\n",
    "    inv_row['relation'] = f\"inv_{row['relation']}\"\n",
    "    inv_facts_rows.append(inv_row)\n",
    "\n",
    "inv_fact_df = pd.DataFrame(inv_facts_rows)\n",
    "inv_fact_df.to_csv(os.path.join(source_data, 'facts.txt.inv'), sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df.iloc[249341:]\n",
    "test_df.to_csv(os.path.join(source_data, 'test.txt'), sep='\\t', header=None, index=False)\n",
    "\n",
    "inv_test_rows = []\n",
    "for _, row in test_df.iterrows():\n",
    "    inv_test_rows.append(row)\n",
    "    inv_row = row.copy()\n",
    "    inv_row['subject'], inv_row['object'] = row['object'], row['subject']\n",
    "    inv_row['relation'] = f\"inv_{row['relation']}\"\n",
    "    inv_test_rows.append(inv_row)\n",
    "\n",
    "inv_test_df = pd.DataFrame(inv_test_rows)\n",
    "inv_test_df.to_csv(os.path.join(source_data, 'test.txt.inv'), sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from datasets/YAGO\\relation2id.json\n"
     ]
    }
   ],
   "source": [
    "relation_list = list(load_json_data(os.path.join(source_data, 'relation2id.json')).keys())\n",
    "write_lines_to_file(os.path.join(source_data, 'relations.txt'), relation_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_DA-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
